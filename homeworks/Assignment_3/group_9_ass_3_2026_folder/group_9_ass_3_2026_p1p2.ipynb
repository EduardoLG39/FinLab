{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27bcf19e",
   "metadata": {},
   "source": [
    "## Lecture 4 — Data (BCRP + Yahoo) + Plots + Stats + VaR \n",
    "\n",
    "Reproduce the key parts of the lecture notebook using:\n",
    "\n",
    "- **Peru (BCRP API)**: `PD04637PD`, `PD04639PD`, `PD04704XD`, `PD04701XD`  \n",
    "  *(FX + commodities exactly as in the notebook)*\n",
    "- **USA (yfinance)**: `SPY`, `TLT`, `GLD`\n",
    "\n",
    "**Deliverables**\n",
    "- Multiple **plots** (including **one with annotations**)  \n",
    "- A **summary statistics table**  \n",
    "- **Historical 95% VaR** for a **60/40 portfolio** (SPY/TLT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2296aa0d",
   "metadata": {},
   "source": [
    "1. Build (and display) the **BCRPData API URL** that requests the 4 series used in the notebook.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbf66e7-30b5-456c-8ae7-6fb0062952bc",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "A clean and explicit setup ensures reproducibility: imports are centralised, the sample window is defined once, and display options are set for consistent outputs across machines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52a78744-7abb-49eb-ae4f-037f47dff239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n",
      "Sample window: 2021-01-01 to 2024-12-31\n",
      "BCRP series: ['PD04637PD', 'PD04639PD', 'PD04704XD', 'PD04701XD']\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Setup — Lecture 4\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Display options for clear tables in Colab\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "# Sample window (as requested)\n",
    "START = \"2021-01-01\"\n",
    "END   = \"2024-12-31\"\n",
    "\n",
    "# BCRP series used in the lecture notebook\n",
    "BCRP_CODES = [\"PD04637PD\", \"PD04639PD\", \"PD04704XD\", \"PD04701XD\"]\n",
    "\n",
    "print(\"Setup complete.\")\n",
    "print(\"Sample window:\", START, \"to\", END)\n",
    "print(\"BCRP series:\", BCRP_CODES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e95d46f-b066-4fb6-813b-aaf794b4d901",
   "metadata": {},
   "source": [
    "Constructing and printing the URL makes the data source **auditable** and the request **replicable**.  \n",
    "The lecture uses the **BCRP Data API** by concatenating series codes with **hyphens (-)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96005a7b-15d4-4270-b847-b937ca389552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCRPData API URL:\n",
      "https://estadisticas.bcrp.gob.pe/estadisticas/series/api/PD04637PD-PD04639PD-PD04704XD-PD04701XD/json/2021-01-01/2024-12-31/ing\n"
     ]
    }
   ],
   "source": [
    "# Build the BCRPData API URL\n",
    "series_str = \"-\".join(BCRP_CODES)\n",
    "bcrp_url = f\"https://estadisticas.bcrp.gob.pe/estadisticas/series/api/{series_str}/json/{START}/{END}/ing\"\n",
    "\n",
    "print(\"BCRPData API URL:\")\n",
    "print(bcrp_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57a494",
   "metadata": {},
   "source": [
    "2. Download those series and build a **tidy** table: `date`, `series`, `value`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da83e42-92d4-4443-a53f-9a7b536b80f4",
   "metadata": {},
   "source": [
    "Before reshaping into a wide time-series table, it is best practice to first organise the raw observations into a tidy (long) structure, where each row corresponds to one observation for one series on one date. This format is transparent, facilitates validation by series, and aligns with standard data-science conventions for clean data pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83cc429d-be1e-4e9e-8b54-a3de47c889c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload keys: ['config', 'periods']\n",
      "Number of periods: 1043\n",
      "First period dict: {'name': '04.Jan.21', 'values': ['3.624', '3.624', '359.177118159863', '1943.2']}\n",
      "First 5 raw dates: ['04.Jan.21', '05.Jan.21', '06.Jan.21', '07.Jan.21', '08.Jan.21']\n"
     ]
    }
   ],
   "source": [
    "# --- Download data from the BCRP API ---\n",
    "response = requests.get(bcrp_url, timeout=60)\n",
    "response.raise_for_status()\n",
    "payload = response.json()\n",
    "\n",
    "# Inspect structure\n",
    "print(\"Payload keys:\", list(payload.keys()))\n",
    "\n",
    "# Ensure periods exist and show first observation\n",
    "assert \"periods\" in payload and len(payload[\"periods\"]) > 0, \"No periods returned. Check URL or date range.\"\n",
    "\n",
    "print(\"Number of periods:\", len(payload[\"periods\"]))\n",
    "print(\"First period dict:\", payload[\"periods\"][0])\n",
    "print(\"First 5 raw dates:\", [p[\"name\"] for p in payload[\"periods\"][:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53b10517-e29e-4431-9117-6506ffcd6971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before dropping NaT: 4172\n",
      "Unparsed dates (NaT): 344\n",
      "\n",
      "Tidy table preview (first 12 rows):\n",
      "      date    series       value\n",
      "2021-01-01 PD04637PD         NaN\n",
      "2021-01-01 PD04639PD         NaN\n",
      "2021-01-01 PD04701XD 1891.100000\n",
      "2021-01-01 PD04704XD  351.148537\n",
      "2021-01-04 PD04637PD    3.624000\n",
      "2021-01-04 PD04639PD    3.624000\n",
      "2021-01-04 PD04701XD 1943.200000\n",
      "2021-01-04 PD04704XD  359.177118\n",
      "2021-01-05 PD04637PD    3.627500\n",
      "2021-01-05 PD04639PD    3.627000\n",
      "2021-01-05 PD04701XD 1940.350000\n",
      "2021-01-05 PD04704XD  358.973002\n",
      "\n",
      "Tidy table shape: (3828, 3)\n",
      "Series present: ['PD04637PD' 'PD04639PD' 'PD04701XD' 'PD04704XD']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22588\\2888885512.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  peru_tidy[\"date\"] = pd.to_datetime(peru_tidy[\"date_clean\"], errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for obs in payload[\"periods\"]:\n",
    "    date_raw = str(obs[\"name\"])\n",
    "    vals = obs[\"values\"]\n",
    "\n",
    "    # Defensive date cleaning:\n",
    "    # - remove time suffix if present (e.g., \"2021-01-04T00:00:00\")\n",
    "    # - strip spaces\n",
    "    date_clean = date_raw.split(\"T\")[0].strip()\n",
    "\n",
    "    for code, val in zip(BCRP_CODES, vals):\n",
    "        rows.append((date_raw, date_clean, code, val))\n",
    "\n",
    "peru_tidy = pd.DataFrame(rows, columns=[\"date_raw\", \"date_clean\", \"series\", \"value_raw\"])\n",
    "\n",
    "# Robust date parsing: do NOT force a single format, because your API output may vary\n",
    "peru_tidy[\"date\"] = pd.to_datetime(peru_tidy[\"date_clean\"], errors=\"coerce\")\n",
    "\n",
    "# Robust numeric parsing\n",
    "peru_tidy[\"value\"] = (\n",
    "    peru_tidy[\"value_raw\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\",\", \".\", regex=False)\n",
    ")\n",
    "peru_tidy[\"value\"] = pd.to_numeric(peru_tidy[\"value\"], errors=\"coerce\")\n",
    "\n",
    "# IMPORTANT: check parsing success BEFORE dropping\n",
    "print(\"Rows before dropping NaT:\", len(peru_tidy))\n",
    "print(\"Unparsed dates (NaT):\", peru_tidy[\"date\"].isna().sum())\n",
    "\n",
    "# Now clean and keep the required tidy columns\n",
    "peru_tidy = (\n",
    "    peru_tidy\n",
    "    .dropna(subset=[\"date\"])\n",
    "    .sort_values([\"date\", \"series\"])\n",
    "    .reset_index(drop=True)\n",
    ")[[\"date\", \"series\", \"value\"]]\n",
    "\n",
    "# Guaranteed print (works even if display fails)\n",
    "print(\"\\nTidy table preview (first 12 rows):\")\n",
    "print(peru_tidy.head(12).to_string(index=False))\n",
    "\n",
    "print(\"\\nTidy table shape:\", peru_tidy.shape)\n",
    "print(\"Series present:\", peru_tidy[\"series\"].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e8f662",
   "metadata": {},
   "source": [
    "3. Clean to **wide format** with columns: `fx_interbank`, `fx_sbs`, `gold`, `copper` (as in the notebook).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dcf214-2156-43f3-b2dd-b1f2d223a8c4",
   "metadata": {},
   "source": [
    "A wide-format table is the standard representation for time-series analysis: it stores one observation per date and one column per variable. This structure facilitates direct comparisons across series, straightforward merging with US asset returns, and transparent econometric modelling. The cleaning step consists of mapping raw BCRP codes to semantically meaningful column names and reshaping the tidy dataset via a pivot operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12ec884d-f45f-43dd-8c37-beb22d4d5ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide table preview:\n",
      "      date  fx_interbank  fx_sbs       gold  copper\n",
      "2021-01-01           NaN     NaN 351.148537 1891.10\n",
      "2021-01-04      3.624000   3.624 359.177118 1943.20\n",
      "2021-01-05      3.627500   3.627 358.973002 1940.35\n",
      "2021-01-06      3.624833   3.625 368.747917 1931.95\n",
      "2021-01-07      3.620667   3.620 364.529508 1920.10\n",
      "2021-01-08      3.611000   3.610 369.496345 1862.90\n",
      "2021-01-11      3.615167   3.615 360.673973 1847.25\n",
      "2021-01-12      3.606333   3.606 362.102789 1841.25\n",
      "2021-01-13      3.612500   3.610 361.082206 1858.85\n",
      "2021-01-14      3.610667   3.610 362.987294 1841.75\n",
      "\n",
      "Wide table shape: (957, 5)\n",
      "Columns: ['date', 'fx_interbank', 'fx_sbs', 'gold', 'copper']\n"
     ]
    }
   ],
   "source": [
    "# --- Map BCRP codes to the lecture notebook variable names ---\n",
    "code_to_name = {\n",
    "    \"PD04637PD\": \"fx_interbank\",\n",
    "    \"PD04639PD\": \"fx_sbs\",\n",
    "    \"PD04704XD\": \"gold\",\n",
    "    \"PD04701XD\": \"copper\",\n",
    "}\n",
    "\n",
    "# Defensive check: confirm all codes are present before reshaping\n",
    "missing = set(code_to_name.keys()) - set(peru_tidy[\"series\"].unique())\n",
    "assert not missing, f\"Missing expected series in peru_tidy: {missing}\"\n",
    "\n",
    "# --- Reshape from tidy (long) to wide (time-series) format ---\n",
    "peru_wide = (\n",
    "    peru_tidy\n",
    "    .assign(series=lambda d: d[\"series\"].map(code_to_name))\n",
    "    .pivot_table(index=\"date\", columns=\"series\", values=\"value\", aggfunc=\"last\")\n",
    "    .sort_index()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Ensure the column order matches the notebook requirement exactly\n",
    "peru_wide = peru_wide[[\"date\", \"fx_interbank\", \"fx_sbs\", \"gold\", \"copper\"]]\n",
    "\n",
    "# Quick inspection\n",
    "print(\"Wide table preview:\")\n",
    "print(peru_wide.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nWide table shape:\", peru_wide.shape)\n",
    "print(\"Columns:\", list(peru_wide.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35e234f",
   "metadata": {},
   "source": [
    "4. Download `SPY`, `TLT`, `GLD` from yfinance and build: `date`, `ticker`, `close`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9224cb63-c2b8-441f-955d-e8b3d5f4ba5b",
   "metadata": {},
   "source": [
    "US financial assets are retrieved using Yahoo Finance via the yfinance package, which is widely adopted in empirical finance for obtaining daily market data. Adjusted prices are used to ensure that the resulting series account for dividends and stock splits, thereby making subsequent return calculations economically meaningful. The data are organised in a tidy (long) format, with one observation per asset and date, which is consistent with best practices for financial time-series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a291baa3-13ff-4752-b619-87686ca42b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty? False\n",
      "Columns names: ['Price', 'Ticker']\n",
      "Columns sample: [('Close', 'GLD'), ('Close', 'SPY'), ('Close', 'TLT'), ('High', 'GLD'), ('High', 'SPY')]\n",
      "\n",
      "US assets (tidy) — preview:\n",
      "      date ticker      close\n",
      "2021-01-04    GLD 182.330002\n",
      "2021-01-04    SPY 344.256714\n",
      "2021-01-04    TLT 134.713715\n",
      "2021-01-05    GLD 182.869995\n",
      "2021-01-05    SPY 346.627716\n",
      "2021-01-05    TLT 133.713226\n",
      "2021-01-06    GLD 179.899994\n",
      "2021-01-06    SPY 348.700073\n",
      "2021-01-06    TLT 130.968384\n",
      "2021-01-07    GLD 179.479996\n",
      "2021-01-07    SPY 353.880859\n",
      "2021-01-07    TLT 129.813950\n",
      "\n",
      "Tidy shape: (3012, 3)\n",
      "Tickers present: ['GLD' 'SPY' 'TLT']\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "USA_TICKERS = [\"SPY\", \"TLT\", \"GLD\"]\n",
    "\n",
    "yf_data = yf.download(\n",
    "    tickers=USA_TICKERS,\n",
    "    start=START,\n",
    "    end=END,\n",
    "    auto_adjust=True,\n",
    "    progress=False\n",
    ")\n",
    "\n",
    "print(\"Empty?\", yf_data.empty)\n",
    "print(\"Columns names:\", getattr(yf_data.columns, \"names\", None))\n",
    "print(\"Columns sample:\", list(yf_data.columns)[:5])\n",
    "\n",
    "# --- Handle MultiIndex with order (Price, Ticker) ---\n",
    "if isinstance(yf_data.columns, pd.MultiIndex):\n",
    "    # Your case: level 0 is Price field, level 1 is Ticker\n",
    "    lvl0 = yf_data.columns.get_level_values(0)\n",
    "    lvl1 = yf_data.columns.get_level_values(1)\n",
    "\n",
    "    if \"Close\" in set(lvl0):\n",
    "        close_wide = yf_data[\"Close\"].copy()     # columns become tickers\n",
    "    elif \"close\" in set(lvl0):\n",
    "        close_wide = yf_data[\"close\"].copy()\n",
    "    else:\n",
    "        raise KeyError(f\"No Close field in level 0. Found level0 fields: {sorted(set(lvl0))}\")\n",
    "\n",
    "    usa_tidy = (\n",
    "        close_wide\n",
    "        .reset_index()\n",
    "        .melt(id_vars=\"Date\", var_name=\"ticker\", value_name=\"close\")\n",
    "        .rename(columns={\"Date\": \"date\"})\n",
    "    )\n",
    "\n",
    "else:\n",
    "    # Single-index fallback\n",
    "    if \"Close\" in yf_data.columns:\n",
    "        usa_tidy = yf_data[[\"Close\"]].rename(columns={\"Close\": \"close\"}).reset_index()\n",
    "    elif \"close\" in yf_data.columns:\n",
    "        usa_tidy = yf_data[[\"close\"]].rename(columns={\"close\": \"close\"}).reset_index()\n",
    "    else:\n",
    "        raise KeyError(f\"No Close column found. Columns: {list(yf_data.columns)}\")\n",
    "\n",
    "    usa_tidy = usa_tidy.rename(columns={\"Date\": \"date\"})\n",
    "    usa_tidy[\"ticker\"] = USA_TICKERS[0]\n",
    "    usa_tidy = usa_tidy[[\"date\", \"ticker\", \"close\"]]\n",
    "\n",
    "# Clean types and order\n",
    "usa_tidy[\"date\"] = pd.to_datetime(usa_tidy[\"date\"])\n",
    "usa_tidy[\"close\"] = pd.to_numeric(usa_tidy[\"close\"], errors=\"coerce\")\n",
    "usa_tidy = (\n",
    "    usa_tidy\n",
    "    .dropna(subset=[\"close\"])\n",
    "    .sort_values([\"date\", \"ticker\"])\n",
    "    .reset_index(drop=True)\n",
    ")[[\"date\", \"ticker\", \"close\"]]\n",
    "\n",
    "print(\"\\nUS assets (tidy) — preview:\")\n",
    "print(usa_tidy.head(12).to_string(index=False))\n",
    "\n",
    "print(\"\\nTidy shape:\", usa_tidy.shape)\n",
    "print(\"Tickers present:\", usa_tidy[\"ticker\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7b653b",
   "metadata": {},
   "source": [
    "5. Compute **daily returns** by ticker (`ret`) and validate there are **no inf values**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b32cf-e063-4d1e-b2e2-d2fbb52fb1ae",
   "metadata": {},
   "source": [
    "Daily returns are computed as percentage changes in adjusted closing prices, which is the standard transformation in empirical finance for analysing asset performance and risk. Returns are calculated by ticker to ensure that observations are not incorrectly mixed across assets. After computing returns, it is essential to validate that no infinite values are present, as these may arise from zero prices or data glitches and would invalidate subsequent statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf637266-9c12-479f-8610-1a8969fb5648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any infinite return values? False\n",
      "\n",
      "US assets with returns — preview:\n",
      "      date ticker      close       ret\n",
      "2021-01-04    GLD 182.330002       NaN\n",
      "2021-01-04    SPY 344.256714       NaN\n",
      "2021-01-04    TLT 134.713715       NaN\n",
      "2021-01-05    GLD 182.869995  0.002962\n",
      "2021-01-05    SPY 346.627716  0.006887\n",
      "2021-01-05    TLT 133.713226 -0.007427\n",
      "2021-01-06    GLD 179.899994 -0.016241\n",
      "2021-01-06    SPY 348.700073  0.005979\n",
      "2021-01-06    TLT 130.968384 -0.020528\n",
      "2021-01-07    GLD 179.479996 -0.002335\n",
      "2021-01-07    SPY 353.880859  0.014857\n",
      "2021-01-07    TLT 129.813950 -0.008815\n"
     ]
    }
   ],
   "source": [
    "# --- Compute daily returns by ticker ---\n",
    "usa_returns = usa_tidy.copy()\n",
    "\n",
    "usa_returns[\"ret\"] = (\n",
    "    usa_returns\n",
    "    .groupby(\"ticker\")[\"close\"]\n",
    "    .pct_change()\n",
    ")\n",
    "\n",
    "# --- Validate: check for infinite values ---\n",
    "has_inf = np.isinf(usa_returns[\"ret\"]).any()\n",
    "print(\"Any infinite return values?\", has_inf)\n",
    "\n",
    "# Replace infinite values with NaN (defensive cleaning)\n",
    "usa_returns.loc[np.isinf(usa_returns[\"ret\"]), \"ret\"] = np.nan\n",
    "\n",
    "# Final check\n",
    "assert not np.isinf(usa_returns[\"ret\"]).any(), \"Infinite values still present in returns!\"\n",
    "\n",
    "# Preview\n",
    "print(\"\\nUS assets with returns — preview:\")\n",
    "print(\n",
    "    usa_returns\n",
    "    .head(12)\n",
    "    .to_string(index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f73213f",
   "metadata": {},
   "source": [
    "6. *(Quantities)* Compare FX levels in Peru: produce a **plot** and a short comment.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fab720c",
   "metadata": {},
   "source": [
    "7. *(Proportions)* Compute the **share of positive-return days** by ticker (USA).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72421adf",
   "metadata": {},
   "source": [
    "8. Plot that share as a **bar chart** and add **labels above each bar** (`annotate`).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3e1b3c",
   "metadata": {},
   "source": [
    "9. *(Distributions)* Compare the distribution of **Peru Gold** vs **GLD** (histogram).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2733a626",
   "metadata": {},
   "source": [
    "10. Add an **ECDF** (if used in the notebook) and comment on what changes vs the histogram.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0045218",
   "metadata": {},
   "source": [
    "11. *(Relationships)* Build `FX_change` and relate it to `SPY_ret` (scatter plot).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb7187",
   "metadata": {},
   "source": [
    "12. Compute the **correlation** between `FX_change` and `SPY_ret` and explain the sign.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e70d25",
   "metadata": {},
   "source": [
    "13. Estimate a simple regression `FX_change ~ SPY_ret` and interpret the coefficient.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df056eeb",
   "metadata": {},
   "source": [
    "14. *(Pandas)* Do a selection exercise: `.iloc` (position-based) vs conditional filtering.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d668cd3",
   "metadata": {},
   "source": [
    "15. Create missing data on purpose in one series and apply imputation (as in the notebook).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cbf0d0",
   "metadata": {},
   "source": [
    "16. Standardize a variable (z-score) and plot **before vs after**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427b70a",
   "metadata": {},
   "source": [
    "17. Find the day with the largest `|SPY_ret|` and **annotate it** in the returns plot (like the exercise).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd02725",
   "metadata": {},
   "source": [
    "18. Save one figure into `/figures` using `savefig` and verify the file exists.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8434335",
   "metadata": {},
   "source": [
    "19. Build a **summary stats table** for returns (mean, sd, p5, p95, etc.).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1bdccc",
   "metadata": {},
   "source": [
    "20. Compute **historical 95% VaR** for a **60/40 portfolio (SPY/TLT)** and explain what it means.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
